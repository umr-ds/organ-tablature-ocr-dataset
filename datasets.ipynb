{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organ Tablature OCR Data Set Creator\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole organ tablature ocr data set requires almost 90GB of disc space, which is why instead of the whole data set we distribute the generator.\n",
    "\n",
    "The following packages need to be installed to run the provided code:\n",
    "* **Numpy**: `pip install numpy`\n",
    "* **Pillow**: `pip install Pillow`\n",
    "* **Augmentor**: `pip install Augmentor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the data set with this notebook\n",
    "\n",
    "By running the following code blocks the complete organ tablature ocr data set will be built.\n",
    "This includes downloading the real tablature staves, running the data generator and running the data augmentor.\n",
    "The parameters (number of images, number of augmentations, ...) set in this notebook are the same as used in the experiments for the paper.\n",
    "They can be changed to build a data set of different size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the data set from command line\n",
    "\n",
    "The downloader, data generator and data augmentor can also be run from command line by calling the `Main`-modules from the `src` directory.\n",
    "* Downloader: `python datasetDownloaderMain.py <args>`\n",
    "* Generator: `python datasetGeneratorMain.py <args>`\n",
    "* Augmentor: `python datasetAugmentorMain.py <args>`\n",
    "\n",
    "The required arguments are specified in the documentations of the respective python modules.\n",
    "To further customize all aspects of the generator and augmentor the variables specified inside the `Main`-modules can be changed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Program Setup\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code sets the `src` folder as the working directory for the program and imports all required methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.basename(os.getcwd()) != 'src':\n",
    "    os.chdir('src')\n",
    "\n",
    "from datasetDownloaderMain import download_dataset\n",
    "from datasetGeneratorMain import generate_dataset\n",
    "from datasetAugmentorMain import augment_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## RealData Download\n",
    "\n",
    "---\n",
    "\n",
    "The annotated realData source images (over 700MB) are downloaded and extraced to `data/realdataSources`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "download_zip_path = \"../data/realdataSources/realdataSources.zip\"\n",
    "download_output_path = \"../data\"\n",
    "download_delete_zip_file = True\n",
    "\n",
    "download_dataset(download_zip_path, download_output_path, download_delete_zip_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Set Generator\n",
    "\n",
    "The data set generator is used to generate artificial tablature staves for the train and validation sets.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_source_folder = \"../data/generatorSources/\"\n",
    "generator_final_augment = False  # the final augmentation step is omitted because augmentation occurs separately later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainSet (20,000 generated images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator_output_folder = \"../data/generatorOutput/trainSetA/\"\n",
    "generator_output_index_start = 0\n",
    "generator_num_of_samples = 20000\n",
    "\n",
    "generate_dataset(input_folder=generator_source_folder,\n",
    "                 output_folder=generator_output_folder,\n",
    "                 generate_num=generator_num_of_samples, \n",
    "                 output_index_start=generator_output_index_start,\n",
    "                 final_augment=generator_final_augment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ValidationSet (8,000 generated images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator_output_folder = \"../data/generatorOutput/validationSetA/\"\n",
    "generator_output_index_start = 0\n",
    "generator_num_of_samples = 8000\n",
    "\n",
    "generate_dataset(input_folder=generator_source_folder,\n",
    "                 output_folder=generator_output_folder,\n",
    "                 generate_num=generator_num_of_samples, \n",
    "                 output_index_start=generator_output_index_start,\n",
    "                 final_augment=generator_final_augment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TestSet (0 generated images)\n",
    "The TestSet only consists of real images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset Augmentor\n",
    "The generated data set is enlarged by using data augmentation.\n",
    "The generated tablature staves are combined with real staves.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainSet (realData: 1,000 images, 100 augmentations per image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "augmentor_input_folder = \"../data/realdataSources/trainSet/\"\n",
    "augmentor_input_indices = (0, 1000)\n",
    "\n",
    "augmentor_output_folder = \"../data/datasetOutput/trainSetA/\"\n",
    "augmentor_num_augmentations = 100\n",
    "augmentor_output_index_start = 0\n",
    "\n",
    "augment_dataset(input_folder=augmentor_input_folder,\n",
    "                input_indices=augmentor_input_indices,\n",
    "                output_folder=augmentor_output_folder, \n",
    "                augment_num=augmentor_num_augmentations,\n",
    "                output_index_start=augmentor_output_index_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainSet (generatedData: 20,000 images, 5 augmentations per image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "augmentor_input_folder = \"../data/generatorOutput/trainSetA/\"\n",
    "augmentor_input_indices = (0, 20000)\n",
    "\n",
    "augmentor_output_folder = \"../data/datasetOutput/trainSetA/\"\n",
    "augmentor_num_augmentations = 5\n",
    "augmentor_output_index_start = 100000\n",
    "\n",
    "augment_dataset(input_folder=augmentor_input_folder,\n",
    "                input_indices=augmentor_input_indices,\n",
    "                output_folder=augmentor_output_folder, \n",
    "                augment_num=augmentor_num_augmentations,\n",
    "                output_index_start=augmentor_output_index_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ValidationSet (realData: 400 images, 25 augmentations per image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor_input_folder = \"../data/realdataSources/validationSet/\"\n",
    "augmentor_input_indices = (0, 400)\n",
    "\n",
    "augmentor_output_folder = \"../data/datasetOutput/validationSetA/\"\n",
    "augmentor_num_augmentations = 25\n",
    "augmentor_output_index_start = 0\n",
    "\n",
    "augment_dataset(input_folder=augmentor_input_folder,\n",
    "                input_indices=augmentor_input_indices,\n",
    "                output_folder=augmentor_output_folder, \n",
    "                augment_num=augmentor_num_augmentations,\n",
    "                output_index_start=augmentor_output_index_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ValidationSet (generatedData: 8,000 images, 5 augmentations per image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor_input_folder = \"../data/generatorOutput/validationSetA/\"\n",
    "augmentor_input_indices = (0, 8000)\n",
    "\n",
    "augmentor_output_folder = \"../data/datasetOutput/validationSetA/\"\n",
    "augmentor_num_augmentations = 5\n",
    "augmentor_output_index_start = 10000\n",
    "\n",
    "augment_dataset(input_folder=augmentor_input_folder,\n",
    "                input_indices=augmentor_input_indices,\n",
    "                output_folder=augmentor_output_folder, \n",
    "                augment_num=augmentor_num_augmentations,\n",
    "                output_index_start=augmentor_output_index_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TestSet (realData: 1,000 images, no augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor_input_folder = \"../data/realdataSources/testSet/\"\n",
    "augmentor_input_indices = (0, 1000)\n",
    "\n",
    "augmentor_output_folder = \"../data/datasetOutput/testSetA/\"\n",
    "augmentor_num_augmentations = 0\n",
    "augmentor_output_index_start = 0\n",
    "\n",
    "augment_dataset(input_folder=augmentor_input_folder,\n",
    "                input_indices=augmentor_input_indices,\n",
    "                output_folder=augmentor_output_folder, \n",
    "                augment_num=augmentor_num_augmentations,\n",
    "                output_index_start=augmentor_output_index_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The `data` directory now contains all tablature images and is structured as follows:\n",
    "* `generatorSources`: Contains source files for the tablature generator\n",
    "    * `backgrounds`: source images for backgrounds and image borders\n",
    "    * `duration`: source images for duration tablature characters\n",
    "    * `note`: source images for note pitch tablature characters\n",
    "    * `rest`: source images for rest tablature characters\n",
    "    * `special`: source images for special tablature characters (measure lines, repetition signs, text blocks, ...)\n",
    "* `realdataSources`: Contains annotated real organ tablature staves from two tablature books by Ammerbach (\"Orgel oder Instrument Tabulaturbuch\" and \"Ein New Künstlich Tabulaturbuch\"). These images will be downloaded in the following.\n",
    "    * `trainSet`: 1000 tablature staves (500 from each book)\n",
    "    * `validationSet`: 400 tablature staves (200 from each book)\n",
    "    * `testSet`: 1000 tablature staves (500 from each book)\n",
    "* `generatorOutput`: Output directory for the data generator\n",
    "    * `trainSetA`: the images generated for the train set (before augmentation)\n",
    "    * `validationSetA`: the images generated for the validation set (before augmentation)\n",
    "* `datasetOutput`: Output directory for the final data sets\n",
    "    * `trainSetA`: the images of the final train set\n",
    "    * `validationSetA`: the images of the final validation set\n",
    "    * `testSetA`: the images of the final test set\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
