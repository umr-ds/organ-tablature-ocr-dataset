{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organ Tablature OCR Dataset Creator\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole organ tablature ocr dataset requires almost 300GB of disc space, which is why instead of the whole dataset the generator is distributed.\n",
    "\n",
    "By running the following code blocks the complete organ tablature ocr dataset will be generated. \n",
    "All source images needed to generate the dataset are provided in the `data` folder.\n",
    "\n",
    "The following packages need to be installed for the generator to work:\n",
    "* **Pillow**: `pip install Pillow`\n",
    "* **Augmentor**: `pip install Augmentor`\n",
    "* **Numpy**: `pip install numpy`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Folder Structure\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `src` folder contains all the python code of the data generator and data augmentor program.\n",
    "\n",
    "The following code sets it as the working directory for the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.basename(os.getcwd()) != 'src':\n",
    "    os.chdir('src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `data` directory contains all tablature images and is structured as follows:\n",
    "* `generatorSources`: Contains source files for the tablature generator\n",
    "    * `backgrounds`: source images for backgrounds and image borders\n",
    "    * `duration`: source images for duration tablature characters\n",
    "    * `note`: source images for note pitch tablature characters\n",
    "    * `rest`: source images for rest tablature characters\n",
    "    * `special`: source images for special tablature characters (measure lines, repetition signs, text blocks, ...)\n",
    "* `realdataSources`: Contains annotated real organ tablature staves from two tablature books by Ammerbach (\"Orgel oder Instrument Tabulaturbuch\" and \"Ein New KÃ¼nstlich Tabulaturbuch\"). These images will be downloaded in the following.\n",
    "    * `trainSet`: 1000 tablature staves (500 from each book)\n",
    "    * `validationSet`: 400 tablature staves (200 from each book)\n",
    "    * `testSet`: 1000 tablature staves (500 from each book)\n",
    "* `generatorOutput`: Output directory for the data generator\n",
    "    * `trainSetA`: the images generated for the train set (before augmentation)\n",
    "    * `validationSetA`: the images generated for the validation set (before augmentation)\n",
    "* `datasetOutput`: Output directory for the final datasets\n",
    "    * `trainSetA`: the images of the final train set\n",
    "    * `validationSetA`: the images of the final validation set\n",
    "    * `testSetA`: the images of the final test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The following script will download the annotated realData source imges (over 700MB) and extract them to the `realdataSources`subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasetGenerator.datasetGenerator.generatorUtility import download_source_images\n",
    "\n",
    "data_url = \"https://box.uni-marburg.de/index.php/s/MENZtcfuWDeDHi8/download\"\n",
    "data_size = 770034652\n",
    "data_output_path = \"../data\"\n",
    "data_zip_path = \"../data3/realdataSources/realdataSources.zip\"\n",
    "\n",
    "download_source_images(data_url, data_size, data_output_path, data_zip_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset Generator\n",
    "\n",
    "The generator is used to generate artificial tablature staves for the train and validation sets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetGenerator.datasetGeneratorMain import generate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_source_folder = \"../data/generatorSources/\"\n",
    "generator_final_augment = False  # the final augmentation step is omitted because augmentation occurs separately later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainSet (140,000 generated images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator_output_folder = \"../data/generatorOutput/trainSetA/\"\n",
    "generator_output_index_start = 0\n",
    "generator_num_of_samples = 140000\n",
    "\n",
    "generate_dataset(input_folder=generator_source_folder,\n",
    "                 output_folder=generator_output_folder,\n",
    "                 generate_num=generator_num_of_samples, \n",
    "                 output_index_start=generator_output_index_start,\n",
    "                 final_augment=generator_final_augment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ValidationSet (8,000 generated images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator_output_folder = \"../data/generatorOutput/validationSetA/\"\n",
    "generator_output_index_start = 0\n",
    "generator_num_of_samples = 8000\n",
    "\n",
    "generate_dataset(input_folder=generator_source_folder,\n",
    "                 output_folder=generator_output_folder,\n",
    "                 generate_num=generator_num_of_samples, \n",
    "                 output_index_start=generator_output_index_start,\n",
    "                 final_augment=generator_final_augment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TestSet (0 generated images)\n",
    "The TestSet only consists of real images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset Augmentor\n",
    "The generated dataset is enlarged by using data augmentation.\n",
    "The generated tablature staves are combined with real staves.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetGenerator.datasetAugmentorMain import augment_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainSet (realData: 1,000 images, 100 augmentations per image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "augmentor_input_folder = \"../data/realdataSources/trainSet/\"\n",
    "augmentor_input_indices = (0, 1000)\n",
    "\n",
    "augmentor_output_folder = \"../data/datasetOutput/trainSetA/\"\n",
    "augmentor_num_augmentations = 100\n",
    "augmentor_output_index_start = 0\n",
    "\n",
    "augment_dataset(input_folder=augmentor_input_folder,\n",
    "                input_indices=augmentor_input_indices,\n",
    "                output_folder=augmentor_output_folder, \n",
    "                augment_num=augmentor_num_augmentations,\n",
    "                output_index_start=augmentor_output_index_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainSet (generatedData: 140,000 images, 5 augmentations per image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "augmentor_input_folder = \"../data/generatorOutput/trainSetA/\"\n",
    "augmentor_input_indices = (0, 140000)\n",
    "\n",
    "augmentor_output_folder = \"../data/datasetOutput/trainSetA/\"\n",
    "augmentor_num_augmentations = 5\n",
    "augmentor_output_index_start = 100000\n",
    "\n",
    "augment_dataset(input_folder=augmentor_input_folder,\n",
    "                input_indices=augmentor_input_indices,\n",
    "                output_folder=augmentor_output_folder, \n",
    "                augment_num=augmentor_num_augmentations,\n",
    "                output_index_start=augmentor_output_index_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ValidationSet (realData: 400 images, 25 augmentations per image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor_input_folder = \"../data/realdataSources/validationSet/\"\n",
    "augmentor_input_indices = (0, 400)\n",
    "\n",
    "augmentor_output_folder = \"../data/datasetOutput/validationSetA/\"\n",
    "augmentor_num_augmentations = 25\n",
    "augmentor_output_index_start = 0\n",
    "\n",
    "augment_dataset(input_folder=augmentor_input_folder,\n",
    "                input_indices=augmentor_input_indices,\n",
    "                output_folder=augmentor_output_folder, \n",
    "                augment_num=augmentor_num_augmentations,\n",
    "                output_index_start=augmentor_output_index_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ValidationSet (generatedData: 8,000 images, 5 augmentations per image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor_input_folder = \"../data/generatorOutput/validationSetA/\"\n",
    "augmentor_input_indices = (0, 8000)\n",
    "\n",
    "augmentor_output_folder = \"../data/datasetOutput/validationSetA/\"\n",
    "augmentor_num_augmentations = 5\n",
    "augmentor_output_index_start = 10000\n",
    "\n",
    "augment_dataset(input_folder=augmentor_input_folder,\n",
    "                input_indices=augmentor_input_indices,\n",
    "                output_folder=augmentor_output_folder, \n",
    "                augment_num=augmentor_num_augmentations,\n",
    "                output_index_start=augmentor_output_index_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TestSet (realData: 1,000 images, no augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor_input_folder = \"../data/realdataSources/testSet/\"\n",
    "augmentor_input_indices = (0, 1000)\n",
    "\n",
    "augmentor_output_folder = \"../data/datasetOutput/testSetA/\"\n",
    "augmentor_num_augmentations = 0\n",
    "augmentor_output_index_start = 0\n",
    "\n",
    "augment_dataset(input_folder=augmentor_input_folder,\n",
    "                input_indices=augmentor_input_indices,\n",
    "                output_folder=augmentor_output_folder, \n",
    "                augment_num=augmentor_num_augmentations,\n",
    "                output_index_start=augmentor_output_index_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The final datasets are found inside the `data/datasetOutput` directory.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
